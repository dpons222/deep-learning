{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "291e6a91",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1dc113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 19:44:59.138323: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-26 19:44:59.497849: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5630e41",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee40d8ad",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e7a5f0",
   "metadata": {},
   "source": [
    "Here we set up BASE_DIR, train_dir, validation_dir, img_height, img_width, batch_size, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac8772f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '__________________'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m validation__________________ \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(validation_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__________________\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Check the contents of the directories\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContents of base directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_DIR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mContents of train directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mlistdir(train_dir)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mContents of validation directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mlistdir(validation_dir)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '__________________'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create variables for the base directory where the data is located, followed by training and validation directories, followed by the class directories \n",
    "'''\n",
    "\n",
    "# Directory that holds the data\n",
    "BASE_DIR = '__________________'\n",
    "\n",
    "# Training directory\n",
    "train_dir = os.path.join(BASE_DIR, 'train')\n",
    "# Validation directory\n",
    "validation_dir = os.path.join(BASE_DIR, 'validation')\n",
    "\n",
    "# Directory with training pictures\n",
    "train__________________ = os.path.join(train_dir, '__________________')\n",
    "train__________________ = os.path.join(train_dir, 'do__________________gs')\n",
    "\n",
    "# Directory with validation pictures\n",
    "validation__________________ = os.path.join(validation_dir, '__________________')\n",
    "validation__________________ = os.path.join(validation_dir, '__________________')\n",
    "\n",
    "# Check the contents of the directories\n",
    "print(f\"Contents of base directory: {os.listdir(BASE_DIR)}\")\n",
    "\n",
    "print(f\"\\nContents of train directory: {os.listdir(train_dir)}\")\n",
    "\n",
    "print(f\"\\nContents of validation directory: {os.listdir(validation_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106b101",
   "metadata": {},
   "source": [
    "## Contants & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d19083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (300, 300)\n",
    "LABEL_MODE = 'binary'\n",
    "\n",
    "# Instantiate the training dataset\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=LABEL_MODE\n",
    ")\n",
    "\n",
    "# Instantiate the validation dataset\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=LABEL_MODE\n",
    ")\n",
    "# Optional: Inspect the dataset here if desired\n",
    "# print(train_dataset.class_names) # See inferred class names\n",
    "# for image_batch, label_batch in train_dataset.take(1):\n",
    "#     print(image_batch.shape)\n",
    "#     print(label_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cabe39",
   "metadata": {},
   "source": [
    "## Data Pipeline Optimization: Apply .cache(), .shuffle(), .prefetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e51f61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m SHUFFLE_BUFFER_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      2\u001b[0m PREFETCH_BUFFER_SIZE \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE\n\u001b[0;32m----> 4\u001b[0m train_dataset_final \u001b[38;5;241m=\u001b[39m (\u001b[43mtrain_dataset\u001b[49m\n\u001b[1;32m      5\u001b[0m                        \u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m      6\u001b[0m                        \u001b[38;5;241m.\u001b[39mshuffle(SHUFFLE_BUFFER_SIZE)\n\u001b[1;32m      7\u001b[0m                        \u001b[38;5;241m.\u001b[39mprefetch(PREFETCH_BUFFER_SIZE)\n\u001b[1;32m      8\u001b[0m                        )\n\u001b[1;32m     10\u001b[0m validation_dataset_final \u001b[38;5;241m=\u001b[39m (validation_dataset\n\u001b[1;32m     11\u001b[0m                             \u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m     12\u001b[0m                             \u001b[38;5;241m.\u001b[39mprefetch(PREFETCH_BUFFER_SIZE)\n\u001b[1;32m     13\u001b[0m                             )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset_final = (train_dataset\n",
    "                       .cache()\n",
    "                       .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                       .prefetch(PREFETCH_BUFFER_SIZE)\n",
    "                       )\n",
    "\n",
    "validation_dataset_final = (validation_dataset\n",
    "                            .cache()\n",
    "                            .prefetch(PREFETCH_BUFFER_SIZE)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d10213",
   "metadata": {},
   "source": [
    "# Create Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Builds a CNN for image binary classification;\n",
    "We are defining a base model function, in case we have to create multiple variations and/or with augmentations before compiling/training models\n",
    "\"\"\"\n",
    "\n",
    "def create_model(): \n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.Input(shape=(300,300,3)),\n",
    "      # This will rescale the image to [0,1]\n",
    "      tf.keras.layers.Rescaling(1./255),\n",
    "      # This is the first convolution\n",
    "      tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      # The second convolution\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      # The third convolution\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      # The fourth convolution\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      # The fifth convolution\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      # Flatten the results to feed into a DNN\n",
    "      tf.keras.layers.Flatten(),\n",
    "      # 512 neuron hidden layer\n",
    "      tf.keras.layers.Dense(512, activation='relu'),\n",
    "      # Last 1 Neuron\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "      ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96302a9",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3937b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fill mode.\n",
    "FILL_MODE = 'nearest'\n",
    "\n",
    "# Create the augmentation model.\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    # Specify the input shape.\n",
    "    tf.keras.Input(shape=(150,150,3)),\n",
    "    # Add the augmentation layers\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2, fill_mode=FILL_MODE),\n",
    "    tf.keras.layers.RandomTranslation(0.2,0.2, fill_mode=FILL_MODE),\n",
    "    tf.keras.layers.RandomZoom(0.2, fill_mode=FILL_MODE)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dda635",
   "metadata": {},
   "source": [
    "### Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Utility function that lets you preview how the transformed images look like. \n",
    " It will take in a sample image, then output a given number of augmented images using the model defined above.\n",
    "\"\"\"\n",
    "\n",
    "def demo_augmentation(sample_image, model, num_aug):\n",
    "    '''Takes a single image array, then uses a model to generate num_aug transformations'''\n",
    "\n",
    "    # Instantiate preview list\n",
    "    image_preview = []\n",
    "\n",
    "    # Convert input image to a PIL image instance\n",
    "    sample_image_pil = tf.keras.utils.array_to_img(sample_image)\n",
    "\n",
    "    # Append the result to the list\n",
    "    image_preview.append(sample_image_pil)\n",
    "\n",
    "    # Apply the image augmentation and append the results to the list\n",
    "    for i in range(NUM_AUG):\n",
    "        sample_image_aug = model(tf.expand_dims(sample_image, axis=0))\n",
    "        sample_image_aug_pil = tf.keras.utils.array_to_img(tf.squeeze(sample_image_aug))\n",
    "        image_preview.append(sample_image_aug_pil)\n",
    "\n",
    "    # Instantiate a subplot\n",
    "    fig, axes = plt.subplots(1, NUM_AUG + 1, figsize=(12, 12))\n",
    "\n",
    "    # Preview the images.\n",
    "    for index, ax in enumerate(axes):\n",
    "        ax.imshow(image_preview[index])\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        if index == 0:\n",
    "            ax.set_title('original')\n",
    "        else:\n",
    "            ax.set_title(f'augment {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images\n",
    "sample_batch = list(train_dataset.take(1))[0][0]\n",
    "print(f'images per batch: {len(sample_batch)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877699a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AUG = 4\n",
    "\n",
    "# Apply the transformations to the first 4 images\n",
    "demo_augmentation(sample_batch[0], data_augmentation, NUM_AUG)\n",
    "demo_augmentation(sample_batch[1], data_augmentation, NUM_AUG)\n",
    "demo_augmentation(sample_batch[2], data_augmentation, NUM_AUG)\n",
    "demo_augmentation(sample_batch[3], data_augmentation, NUM_AUG)\n",
    "\n",
    "# Uncomment the line below to delete the variable to free up some memory\n",
    "# del sample_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22d477f",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018eafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the base model\n",
    "model = create_model()\n",
    "model2 = create_model()\n",
    "\n",
    "# Prepend the data augmentation layers to the base model\n",
    "model_with_aug = tf.keras.models.Sequential([\n",
    "    data_augmentation,\n",
    "    model2\n",
    "])\n",
    "\n",
    "# Any more augmentations? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a6069",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile( \n",
    "        optimizer=tf.keras.optimizers.RMSprop(),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d88e9",
   "metadata": {},
   "source": [
    "## variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c17547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_with_aug.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd89236",
   "metadata": {},
   "source": [
    "# EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d200c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    # Define the correct function signature for on_epoch_end method\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Check if the accuracy is greater or equal to 0.95 and validation accuracy is greater or equal to 0.8\n",
    "        if logs['accuracy'] >= 0.95 and logs['val_accuracy'] >= 0.80:\n",
    "            print(\"\\nReached 95% train accuracy and 80% validation accuracy, so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda915e8",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and save the training history (this may take some time)\n",
    "history = model.fit(\n",
    "\ttrain_dataset_final,\n",
    "\tepochs=15,\n",
    "\tvalidation_data=validation_dataset_final,\n",
    "\tcallbacks = [EarlyStoppingCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bff3d2",
   "metadata": {},
   "source": [
    "## variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c5b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and save the training history (this may take some time)\n",
    "history_with_aug = model_with_aug.fit(\n",
    "\ttrain_dataset_final,\n",
    "\tepochs=15,\n",
    "\tvalidation_data=validation_dataset_final,\n",
    "\tcallbacks = [EarlyStoppingCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e6abf9",
   "metadata": {},
   "source": [
    "# Plot Training and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510b9c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get training and validation accuracies\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_loss_acc(history):\n",
    "    \"\"\"Plots the training and validation loss and accuracy from a history object\"\"\"\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Get number of epochs\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    fig.suptitle('Training and validation accuracy')\n",
    "\n",
    "    for i, (data, label) in enumerate(zip([(acc, val_acc), (loss, val_loss)], [\"Accuracy\", \"Loss\"])):\n",
    "        ax[i].plot(epochs, data[0], 'r', label=\"Training \" + label)\n",
    "        ax[i].plot(epochs, data[1], 'b', label=\"Validation \" + label)\n",
    "        ax[i].legend()\n",
    "        ax[i].set_xlabel('epochs')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea513386",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_acc(history_with_aug)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
